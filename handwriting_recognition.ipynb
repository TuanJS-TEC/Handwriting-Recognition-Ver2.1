{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec96606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minhtuansfile/HoangTuan_Code/XLA_BTL/venv/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1421 - val_accuracy: 0.9835 - val_loss: 0.0514\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0479 - val_accuracy: 0.9889 - val_loss: 0.0337\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0334 - val_accuracy: 0.9826 - val_loss: 0.0499\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0242 - val_accuracy: 0.9893 - val_loss: 0.0316\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.9899 - val_loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "model = models.Sequential([\n",
    "layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "layers.MaxPooling2D((2,2)),\n",
    "layers.Conv2D(64, (3,3), activation='relu'),\n",
    "layers.MaxPooling2D((2,2)),\n",
    "layers.Flatten(),\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "model.save('mnist_model.h5')\n",
    "print(\"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfdb16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh CNN trÃªn MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab800e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "\n",
    "try:\n",
    "    model = load_model('mnist_model.h5', compile=False)\n",
    "except IOError:\n",
    "    print(\"Lá»–I: KhÃ´ng tÃ¬m tháº¥y file 'mnist_model.h5'. HÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ Ä‘áº·t file model vÃ o Ä‘Ãºng thÆ° má»¥c.\")\n",
    "\n",
    "def predict_image(img):\n",
    "    try:\n",
    "        if img is None:\n",
    "            return \"Vui lÃ²ng váº½ má»™t sá»‘ trÆ°á»›c.\"\n",
    "        if isinstance(img, str):\n",
    "            try:\n",
    "                img = json.loads(img)\n",
    "            except json.JSONDecodeError:\n",
    "                return \"Dá»¯ liá»‡u Flag khÃ´ng há»£p lá»‡ (khÃ´ng pháº£i JSON).\"\n",
    "        if isinstance(img, dict):\n",
    "            if \"composite\" in img and img[\"composite\"] is not None:\n",
    "                img_data = img[\"composite\"]\n",
    "\n",
    "                if isinstance(img_data, str):\n",
    "                    if os.path.exists(img_data):\n",
    "                        img = cv2.imread(img_data, cv2.IMREAD_UNCHANGED)\n",
    "                    else:\n",
    "                        return f\"KhÃ´ng tÃ¬m tháº¥y file áº£nh (Flag): {img_data}\"\n",
    "                elif isinstance(img_data, np.ndarray):\n",
    "                    img = img_data  \n",
    "                else:\n",
    "                    return f\"Dá»¯ liá»‡u 'composite' khÃ´ng xÃ¡c Ä‘á»‹nh: {type(img_data)}\"\n",
    "            else:\n",
    "                return \"KhÃ´ng cÃ³ áº£nh há»£p lá»‡ trong dá»¯ liá»‡u Flag.\"\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        if not isinstance(img, np.ndarray):\n",
    "            return f\"Dá»¯ liá»‡u áº£nh khÃ´ng xÃ¡c Ä‘á»‹nh: {type(img)}\"\n",
    "        if len(img.shape) == 3:\n",
    "            if img.shape[-1] == 4:\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n",
    "            elif img.shape[-1] == 3:\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                img_gray = img[:,:,0] \n",
    "        else:\n",
    "            img_gray = img\n",
    "\n",
    "        img_resized = cv2.resize(img_gray, (28, 28))\n",
    "\n",
    "        img_inverted = cv2.bitwise_not(img_resized)\n",
    "\n",
    "        img_norm = img_inverted / 255.0\n",
    "        img_input = img_norm.reshape(1, 28, 28, 1)\n",
    "\n",
    "        pred = model.predict(img_input)\n",
    "        result = np.argmax(pred)\n",
    "        conf = np.max(pred)\n",
    "        return f\"ğŸ§  MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n: {result} (Ä‘á»™ tin cáº­y: {conf:.2f})\"\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return f\"Lá»—i xá»­ lÃ½ áº£nh: {str(e)}\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "\n",
    "    inputs=gr.Sketchpad(label=\"Váº½ sá»‘ cá»§a báº¡n\", type=\"numpy\"), \n",
    "    \n",
    "    outputs=gr.Textbox(label=\"Káº¿t quáº£ dá»± Ä‘oÃ¡n\"),\n",
    "    title=\"Nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay (MNIST)\",\n",
    "    description=\"Váº½ má»™t sá»‘ (0â€“9) báº±ng chuá»™t, sau Ä‘Ã³ nháº¥n Submit Ä‘á»ƒ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n.\",\n",
    ")\n",
    "\n",
    "# 4. Cháº¡y\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
